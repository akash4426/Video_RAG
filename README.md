# ğŸ¥ Video RAG: Semantic Video Search & AI Summarization

<div align="center">

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repository-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/akash4426/Video_RAG)
[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

**Transform your videos into searchable, explainable knowledge with AI**

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [How It Works](#-how-it-works)

</div>

---

## ğŸŒŸ Overview

Video RAG is a powerful **Retrieval-Augmented Generation** system that enables semantic search within videos using natural language. Simply upload a video, ask a question, and get relevant frames with AI-generated summariesâ€”no manual scrubbing required!

### ğŸ¯ What Makes This Special?

- ğŸ” **Natural Language Search**: Query videos like "person wearing red jacket" or "car accident"
- âš¡ **Lightning Fast**: FAISS-powered similarity search through thousands of frames
- ğŸ§  **AI Summaries**: Context-aware explanations powered by Google's Gemini
- ğŸ¬ **Video Clips**: Extract and download specific scenes automatically
- ğŸ’¾ **Smart Caching**: Process once, search instantly on subsequent runs

---

## âœ¨ Features

### Core Capabilities

| Feature | Description |
|---------|-------------|
| ğŸï¸ **Multi-Format Support** | Upload `.mp4`, `.mov`, `.avi` videos |
| âš™ï¸ **Configurable Sampling** | Adjust FPS (0.5-5) for speed vs. accuracy trade-off |
| ğŸ” **Semantic Search** | CLIP-powered understanding of visual content |
| ğŸ“Š **Visual Results** | Storyboard view + individual frames with timestamps |
| ğŸ¬ **Clip Extraction** | Download matched video segments |
| ğŸ’¬ **AI Summaries** | Gemini-generated contextual explanations |
| ğŸ—‚ï¸ **Smart Caching** | Skip re-processing for previously analyzed videos |

### Advanced Features

- **Batch Processing**: Efficient GPU utilization for large videos
- **Progress Tracking**: Real-time feedback during processing
- **Multiple Models**: Choose between CLIP variants for different use cases
- **Responsive UI**: Clean, intuitive interface with sidebar controls

---

## ğŸ¬ Demo

### Example Workflow

```
1. Upload: city_traffic.mp4
2. Query: "red car at intersection"
3. Results: 3 matched frames at [0:45, 1:23, 2:08]
4. Summary: "A red sedan waits at a traffic light during rush hour..."
```

### Screenshots

<details>
<summary>ğŸ“¸ Click to view screenshots</summary>

**Search Interface**
![Search Interface](screenshots/interface.png)

**Frame Results**
![Frame Results](screenshots/results.png)

**AI Summary**
![AI Summary](screenshots/summary.png)

</details>

> ğŸ’¡ **Tip**: Add actual screenshots to a `screenshots/` folder in your repo

---

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- 4GB+ RAM recommended
- (Optional) GPU for faster processing

### Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/akash4426/Video_RAG.git
cd Video_RAG

# 2. Create virtual environment
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
.\venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
streamlit run app.py
```

### System Dependencies

**macOS:**
```bash
brew install ffmpeg
```

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install ffmpeg libsm6 libxext6 libgl1
```

**Windows:**
Download FFmpeg from [ffmpeg.org](https://ffmpeg.org/download.html) and add to PATH

---

## ğŸ”‘ Configuration

### Gemini API Setup

1. Get your API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Add to Streamlit secrets:

**Local Development:**
Create `.streamlit/secrets.toml`:
```toml
GEMINI_API_KEY = "your-api-key-here"
```

**Streamlit Cloud:**
- Go to App Settings â†’ Secrets
- Add: `GEMINI_API_KEY = "your-key"`

### Environment Variables

```bash
# Optional: Set cache directory
export VIDEORAG_CACHE_DIR=/path/to/cache

# Optional: Set device
export TORCH_DEVICE=cuda  # or cpu, mps
```

---

## ğŸ“– Usage

### Basic Search

```python
# 1. Upload video through UI
# 2. Enter query: "person walking dog"
# 3. View matched frames + timestamps
# 4. Generate AI summary (optional)
```

### Advanced Options

| Setting | Description | Default |
|---------|-------------|---------|
| **Model** | CLIP variant | `clip-vit-base-patch32` |
| **Sampling FPS** | Frames per second | 1.0 |
| **Batch Size** | GPU batch processing | 16 |
| **Top K** | Number of results | 3 |
| **Clip Window** | Context duration (sec) | 2.0 |

### Example Queries

- âœ… "person wearing blue shirt"
- âœ… "car accident on highway"
- âœ… "sunset over ocean"
- âœ… "group of people dancing"
- âŒ "the color blue" (too abstract)
- âŒ "video from 2020" (no temporal reasoning)

---

## ğŸ§  How It Works

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Video Input â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frame Extractionâ”‚  â† OpenCV samples at specified FPS
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLIP Embeddings â”‚  â† Convert frames to 512-D vectors
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FAISS Indexing â”‚  â† Build similarity search index
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Query     â”‚  â† User input converted to embedding
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Similarity      â”‚  â† Find nearest neighbors
â”‚ Search          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini Summary  â”‚  â† Generate natural language explanation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Technologies

#### 1. **CLIP (OpenAI)**
- **Purpose**: Multimodal embeddings (vision + language)
- **How**: Contrastive learning on 400M image-text pairs
- **Output**: 512-dimensional vectors for both images and text

#### 2. **FAISS (Facebook AI)**
- **Purpose**: Efficient similarity search
- **How**: Approximate nearest neighbor algorithms
- **Speed**: Sub-millisecond search on millions of vectors

#### 3. **Gemini (Google)**
- **Purpose**: Multimodal AI summarization
- **How**: Analyzes multiple frames + text context
- **Output**: Natural language descriptions

### Performance

| Metric | Value |
|--------|-------|
| **1 min video @ 1 FPS** | ~60 frames, 2-3 sec processing |
| **Search latency** | < 100ms |
| **Memory usage** | ~500MB + video size |
| **Cache size** | ~7MB per hour of video |

---

## ğŸ§© Project Structure

```
Video_RAG/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ packages.txt          # System dependencies
â”œâ”€â”€ runtime.txt           # Python version
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ config.toml       # UI configuration
â”‚   â””â”€â”€ secrets.toml      # API keys (gitignored)
â”œâ”€â”€ screenshots/          # Demo images
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ“Š Comparison with Alternatives

| Feature | Video RAG | YouTube Search | Manual Scrubbing |
|---------|-----------|----------------|------------------|
| Semantic Understanding | âœ… | âš ï¸ Metadata only | âŒ |
| Speed | âœ… Instant | âœ… | âŒ Very slow |
| Offline Support | âœ… | âŒ | âœ… |
| AI Summaries | âœ… | âŒ | âŒ |
| Custom Videos | âœ… | âŒ Public only | âœ… |

---

## ğŸ› ï¸ Development

### Running Tests

```bash
# Install dev dependencies
pip install pytest pytest-cov

# Run tests
pytest tests/

# With coverage
pytest --cov=app tests/
```

### Code Quality

```bash
# Format code
black app.py

# Lint
flake8 app.py

# Type checking
mypy app.py
```

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

### Ways to Contribute

- ğŸ› **Report bugs** via [Issues](https://github.com/akash4426/Video_RAG/issues)
- ğŸ’¡ **Suggest features** through [Discussions](https://github.com/akash4426/Video_RAG/discussions)
- ğŸ“ **Improve documentation**
- ğŸ”§ **Submit pull requests**

### Development Workflow

```bash
# 1. Fork the repository
# 2. Create feature branch
git checkout -b feature/amazing-feature

# 3. Make changes and commit
git commit -m "Add amazing feature"

# 4. Push to your fork
git push origin feature/amazing-feature

# 5. Open a Pull Request
```

---

## ğŸ“ Use Cases

### ğŸ“ Education
- Navigate lecture videos by topic
- Find specific demonstrations or examples

### ğŸ¬ Content Creation
- Locate B-roll footage quickly
- Find specific scenes for editing

### ğŸ”’ Security
- Search surveillance footage by description
- Incident investigation and analysis

### ğŸ“Š Research
- Analyze video datasets semantically
- Extract frames for annotation

### ğŸ¢ Business
- Meeting recap and highlight extraction
- Training video search and organization

---

## ğŸš§ Roadmap

- [ ] Multi-video search across video library
- [ ] Object tracking across frames
- [ ] Audio transcription integration (Whisper)
- [ ] OCR for on-screen text
- [ ] Export results as JSON/CSV
- [ ] Docker containerization
- [ ] REST API endpoint
- [ ] Mobile-responsive UI

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [OpenAI CLIP](https://github.com/openai/CLIP) for multimodal embeddings
- [Facebook FAISS](https://github.com/facebookresearch/faiss) for similarity search
- [Google Gemini](https://ai.google.dev/) for AI summaries
- [Streamlit](https://streamlit.io/) for the amazing framework

---

## ğŸ‘¤ Author

**Akash Karri**

- ğŸ“§ Email: akashkarri2006@gmail.com
- ğŸ’¼ LinkedIn: [LinkedIn Profile](https://linkedin.com/in/akash4426)
- ğŸ™ GitHub: [@akash4426](https://github.com/akash4426)

---

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=akash4426/Video_RAG&type=Date)](https://star-history.com/#akash4426/Video_RAG&Date)

---

## ğŸ“ˆ Stats

![GitHub stars](https://img.shields.io/github/stars/akash4426/Video_RAG?style=social)
![GitHub forks](https://img.shields.io/github/forks/akash4426/Video_RAG?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/akash4426/Video_RAG?style=social)

---

<div align="center">

Made with â¤ï¸ by Akash Karri

If you found this project helpful, consider giving it a â­!

[Report Bug](https://github.com/akash4426/Video_RAG/issues) â€¢ [Request Feature](https://github.com/akash4426/Video_RAG/issues)

</div>

